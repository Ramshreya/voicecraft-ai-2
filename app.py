import streamlit as st
import base64
import requests
import edge_tts
import asyncio
from deep_translator import GoogleTranslator

async def generate_edge_speech(text, voice):
    communicate = edge_tts.Communicate(text=text, voice=voice)
    await communicate.save("output.mp3")
    return "output.mp3"



# ---------- PAGE CONFIG ----------
st.set_page_config(
    page_title="VoiceCraft AI",
    page_icon="ğŸ§",
    layout="centered"
)

# ---------- CUSTOM CSS (PRO LOOK) ----------
st.markdown("""
<style>
.main-title {
    text-align: center;
    font-size: 42px;
    font-weight: 700;
    color: #e6f2ff;
    margin-bottom: 10px;
}

.subtitle {
    text-align: center;
    font-size: 18px;
    color: #9ec9ff;
    margin-bottom: 30px;
}

.stButton>button {
    background-color: #4fc3f7;
    color: black;
    font-weight: 600;
    border-radius: 10px;
    padding: 0.6em 1.2em;
}

.stDownloadButton>button {
    border-radius: 10px;
    font-weight: 600;
}
</style>
""", unsafe_allow_html=True)

# ---------- HEADER ----------
st.markdown('<div class="main-title">ğŸ§ VoiceCraft AI</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">âœ¨ Convert your text into natural speech instantly</div>', unsafe_allow_html=True)

# ---------- TEXT INPUT ----------
text = st.text_area("ğŸ“ Enter your text", height=150)
# ğŸŒ Translate language selector
translate_options = {
    "ğŸ‡ºğŸ‡¸ English": "en",
    "ğŸ‡®ğŸ‡³ Hindi": "hi",
    "ğŸŒ¸ Telugu": "te",
    "ğŸ¶ Tamil": "ta",
    "ğŸª” Bengali": "bn",
    "ğŸ’  Gujarati": "gu",
    "ğŸµ Kannada": "kn",
    "ğŸŒ¿ Malayalam": "ml",
    "ğŸª¶ Punjabi": "pa"
}

target_lang_name = st.selectbox(
    "ğŸŒ Translate text to",
    list(translate_options.keys())
)

target_lang = translate_options[target_lang_name]

# ---------- LANGUAGES ----------
voices = {
    "ğŸ‡ºğŸ‡¸ English (Female)": "en-US-JennyNeural",
    "ğŸ‡ºğŸ‡¸ English (Male)": "en-US-GuyNeural",
    "ğŸ‡®ğŸ‡³ Hindi (Female)": "hi-IN-SwaraNeural",
    "ğŸ‡®ğŸ‡³ Hindi (Male)": "hi-IN-MadhurNeural",
    "ğŸŒ¸ Telugu": "te-IN-ShrutiNeural",
    "ğŸ¶ Tamil": "ta-IN-PallaviNeural",
    "ğŸª” Bengali": "bn-IN-TanishaaNeural",
    "ğŸ’  Gujarati": "gu-IN-DhwaniNeural",
    "ğŸµ Kannada": "kn-IN-SapnaNeural",
    "ğŸŒ¿ Malayalam": "ml-IN-SobhanaNeural",
    "ğŸª¶ Punjabi": "pa-IN-GaganNeural"
}

# ğŸ¯ auto voice mapping based on translate language
auto_voice_map = {
    "en": "en-US-JennyNeural",
    "hi": "hi-IN-SwaraNeural",
    "te": "te-IN-ShrutiNeural",
    "ta": "ta-IN-PallaviNeural",
    "bn": "bn-IN-TanishaaNeural",
    "gu": "gu-IN-DhwaniNeural",
    "kn": "kn-IN-SapnaNeural",
    "ml": "ml-IN-SobhanaNeural",
    "pa": "pa-IN-GaganNeural"
}
# ğŸ“ Show translated text
translated_text = ""

if text.strip():
    try:
        if target_lang != "en":
            translated_text = GoogleTranslator(
                source="auto",
                target=target_lang
            ).translate(text)
        else:
            translated_text = text
    except:
        translated_text = text

st.text_area(
    "ğŸ“ Translated text",
    value=translated_text,
    height=120,
    disabled=True
)

# ğŸ”Š auto-select voice based on translation language
voice = auto_voice_map.get(target_lang, "en-US-JennyNeural")


st.markdown("<br>", unsafe_allow_html=True)

# ---------- GENERATE ----------
if st.button("ğŸ”Š Generate Speech"):

    if text.strip():

        with st.spinner("ğŸ™ï¸ Generating your audio..."):

            
            
            
            # ğŸ”Š then generate speech
            # ğŸ”Š generate speech using already translated text
            file_path = asyncio.run(generate_edge_speech(translated_text, voice))
            if file_path:
              # ğŸ”¥ AUTO PLAY
              with open(file_path, "rb") as f:
                audio_bytes = f.read()
                b64 = base64.b64encode(audio_bytes).decode()

                audio_html = f"""
                    <audio autoplay controls style="width:100%;">
                    <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
                    </audio>
                """
                st.markdown(audio_html, unsafe_allow_html=True)

              # download
              with open(file_path, "rb") as f:
                st.download_button(
                  label="â¬‡ï¸ Download MP3",
                  data=f,
                  file_name="voicecraft_output.mp3",
                  mime="audio/mp3"
                )
            else:
              st.error("âŒ Audio generation failed. Check API key.")


            

            

